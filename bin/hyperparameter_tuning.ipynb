{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import darts\n",
    "from darts.dataprocessing.transformers.boxcox import BoxCox\n",
    "from darts.models import LightGBMModel, XGBModel, LinearRegressionModel, NBEATSModel, BlockRNNModel, RandomForest\n",
    "from darts.metrics import smape, mape, mase, mse, rmse, r2_score, mae\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler   \n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.utils.missing_values import extract_subseries\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from wandb.xgboost import WandbCallback\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from train_eval import *\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\"\n",
    "dir_path = os.path.join(os.getcwd(), 'data', 'clean_data')\n",
    "model_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_light():\n",
    "\n",
    "    wandb.init(project=\"WattCast_tuning\")\n",
    "    wandb.config.update(config_run)\n",
    "    config = wandb.config\n",
    "\n",
    "    print(\"Getting data...\")\n",
    "\n",
    "    pipeline, ts_train_piped, ts_val_piped, ts_test_piped, ts_train_weather_piped, ts_val_weather_piped, ts_test_weather_piped, trg_train_inversed, trg_val_inversed, trg_test_inversed = data_pipeline(config)\n",
    "\n",
    "    print(\"Getting model instance...\")\n",
    "    model = get_model_instance(config)\n",
    "    model, runtime = train_models([model], ts_train_piped, ts_train_weather_piped, ts_val_piped, ts_val_weather_piped)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    predictions, score = predict_testset(model[0], \n",
    "                                  ts_test_piped[config.longest_ts_test_idx], \n",
    "                                  ts_test_weather_piped[config.longest_ts_test_idx],\n",
    "                                  config.n_lags, config.n_ahead, config.eval_stride, pipeline,\n",
    "                                  )\n",
    "\n",
    "\n",
    "    print(\"Plotting predictions...\")\n",
    "    df_compare = pd.concat([trg_test_inversed.pd_dataframe(), predictions], axis=1).dropna()\n",
    "    df_compare.columns = ['target', 'prediction']\n",
    "    fig = px.line(df_compare, title='Predictions vs. Test Set')\n",
    "\n",
    "    wandb.log({'eval_loss': score})\n",
    "    wandb.log({'predictions': fig})\n",
    "    wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'1_county.h5': ['Los_Angeles', 'New_York', 'Sacramento'],\n",
       "  '2_town.h5': ['town_0', 'town_1', 'town_2'],\n",
       "  '3_village.h5': ['village_0', 'village_1', 'village_2'],\n",
       "  '4_neighborhood.h5': ['germany'],\n",
       "  '5_household.h5': ['household_0', 'household_1', 'household_2'],\n",
       "  '6_apartment.h5': ['apartment_0', 'apartment_1', 'apartment_2']},\n",
       " {'1_county.h5': ['60min'],\n",
       "  '2_town.h5': ['15min', '60min'],\n",
       "  '3_village.h5': ['15min', '60min'],\n",
       "  '4_neighborhood.h5': ['15min', '60min'],\n",
       "  '5_household.h5': ['15min', '60min'],\n",
       "  '6_apartment.h5': ['15min', '5min', '60min']})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what keys are in the h5py data file\n",
    "get_hdf_keys(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run parameters\n",
    "\n",
    "sweeps = 20\n",
    "\n",
    "scale_location_pairs = (\n",
    "    ('4_neighborhood', 'germany'),\n",
    "     ('5_household', 'household_0'),\n",
    "      )\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "        'rf',\n",
    "        'xgb', \n",
    "        'gru', \n",
    "        'lgbm',  \n",
    "        'nbeats'\n",
    "        ]\n",
    "\n",
    "for scale, location in scale_location_pairs:\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        config_run = {\n",
    "            'spatial_scale': scale,\n",
    "            'temp_resolution': 60,\n",
    "            'location': location,\n",
    "            'model': model,\n",
    "            'horizon_in_hours': 24,\n",
    "            'lookback_in_hours': 24,\n",
    "            'boxcox': True,\n",
    "            'liklihood': None,\n",
    "            'weather': True,\n",
    "            'holiday': True,\n",
    "            'datetime_encodings': False,\n",
    "        }\n",
    "\n",
    "        with open(f'sweep_configurations/config_sweep_{model}.json', 'r') as fp:\n",
    "            sweep_config = json.load(fp)                  \n",
    "\n",
    "        sweep_config['name'] = model + 'sweep' + config_run['spatial_scale'] + '_' + config_run['location'] + '_' + str(config_run['temp_resolution'])\n",
    "\n",
    "        sweep_id = wandb.sweep(sweep_config, project=\"WattCast_tuning\")\n",
    "        wandb.agent(sweep_id, train_eval_light, count=sweeps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
