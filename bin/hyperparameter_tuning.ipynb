{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwandb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m WandbCallback\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain_eval\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import darts\n",
    "from darts.dataprocessing.transformers.boxcox import BoxCox\n",
    "from darts.models import LightGBMModel, XGBModel, LinearRegressionModel, NBEATSModel, BlockRNNModel, RandomForest\n",
    "from darts.metrics import smape, mape, mase, mse, rmse, r2_score, mae\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler   \n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.utils.missing_values import extract_subseries\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from wandb.xgboost import WandbCallback\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from train_eval import *\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\"\n",
    "dir_path = os.path.join(os.getcwd(), 'data', 'clean_data')\n",
    "model_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_light():\n",
    "\n",
    "    wandb.init(project=\"WattCast_tuning\")\n",
    "    wandb.config.update(config_run)\n",
    "    config = wandb.config\n",
    "\n",
    "    print(\"Getting data...\")\n",
    "\n",
    "    pipeline, ts_train_piped, ts_val_piped, ts_test_piped, ts_train_weather_piped, ts_val_weather_piped, ts_test_weather_piped, trg_train_inversed, trg_val_inversed, trg_test_inversed = data_pipeline(config)\n",
    "\n",
    "    print(\"Getting model instance...\")\n",
    "    model = get_model_instance(config)\n",
    "    model, runtime = train_models([model], ts_train_piped, ts_train_weather_piped, ts_val_piped, ts_val_weather_piped)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    predictions, score = predict_testset(model[0], \n",
    "                                  ts_test_piped[config.longest_ts_test_idx], \n",
    "                                  ts_test_weather_piped[config.longest_ts_test_idx],\n",
    "                                  config.n_lags, config.n_ahead, config.eval_stride, pipeline,\n",
    "                                  )\n",
    "\n",
    "\n",
    "    print(\"Plotting predictions...\")\n",
    "    df_compare = pd.concat([trg_test_inversed.pd_dataframe(), predictions], axis=1).dropna()\n",
    "    df_compare.columns = ['target', 'prediction']\n",
    "    fig = px.line(df_compare, title='Predictions vs. Test Set')\n",
    "\n",
    "    wandb.log({'eval_loss': score})\n",
    "    wandb.log({'predictions': fig})\n",
    "    wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1_county.h5': ['Los_Angeles', 'New_York', 'Sacramento'], '2_town.h5': ['town_0', 'town_1', 'town_2'], '3_village.h5': ['village_0', 'village_1', 'village_2'], '4_neighborhood.h5': ['germany'], '5_household.h5': ['household_0', 'household_1', 'household_2'], '6_apartment.h5': ['apartment_0', 'apartment_1', 'apartment_2']}\n",
      "{'1_county.h5': ['60min'], '2_town.h5': ['15min', '60min'], '3_village.h5': ['15min', '60min'], '4_neighborhood.h5': ['15min', '60min'], '5_household.h5': ['15min', '60min'], '6_apartment.h5': ['15min', '5min', '60min']}\n"
     ]
    }
   ],
   "source": [
    "# See what keys are in the h5py data file\n",
    "show_keys(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run parameters\n",
    "\n",
    "sweeps = 20\n",
    "\n",
    "scale_location_pairs = (\n",
    "    ('4_neighborhood', 'germany'),\n",
    "     ('5_household', 'household_0'),\n",
    "      )\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "        'rf',\n",
    "        'xgb', \n",
    "        'gru', \n",
    "        'lgbm',  \n",
    "        'nbeats'\n",
    "        ]\n",
    "\n",
    "for scale, location in scale_location_pairs:\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        config_run = {\n",
    "            'spatial_scale': scale,\n",
    "            'temp_resolution': 60,\n",
    "            'location': location,\n",
    "            'model': model,\n",
    "            'horizon_in_hours': 24,\n",
    "            'lookback_in_hours': 24,\n",
    "            'boxcox': True,\n",
    "            'liklihood': None,\n",
    "            'weather': True,\n",
    "            'holiday': True,\n",
    "            'datetime_encodings': False,\n",
    "        }\n",
    "\n",
    "        with open(f'sweep_configurations/config_sweep_{model}.json', 'r') as fp:\n",
    "            sweep_config = json.load(fp)                  \n",
    "\n",
    "        sweep_config['name'] = model + 'sweep' + config_run['spatial_scale'] + '_' + config_run['location'] + '_' + str(config_run['temp_resolution'])\n",
    "\n",
    "        sweep_id = wandb.sweep(sweep_config, project=\"WattCast_tuning\")\n",
    "        wandb.agent(sweep_id, train_eval_light, count=sweeps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
