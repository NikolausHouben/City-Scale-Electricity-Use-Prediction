{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import darts\n",
    "from darts.dataprocessing.transformers.boxcox import BoxCox\n",
    "from darts.models import LightGBMModel, XGBModel, LinearRegressionModel, NBEATSModel, BlockRNNModel\n",
    "from darts.metrics import smape, mape, mase, mse, rmse, r2_score, mae\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler   \n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.utils.missing_values import extract_subseries\n",
    "\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from wandb.xgboost import WandbCallback\n",
    "\n",
    "\n",
    "from utils import *\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\"\n",
    "dir_path = os.path.join(os.getcwd(), 'data', 'clean_data')\n",
    "model_dir = os.path.join(os.getcwd(), 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run parameters\n",
    "\n",
    "models = ['xgb', 'gru', 'lgbm', 'linear', 'nbeats']\n",
    "\n",
    "model = models[1]\n",
    "\n",
    "scale_location_pairs = (('1_county', 'Los_Angeles'), ('2_town', 'town_0'), ('3_neighborhood', 'germany'))\n",
    "\n",
    "pair_1 = scale_location_pairs[0]\n",
    "\n",
    "config_run = {\n",
    "    'spatial_scale': pair_1[0],\n",
    "    'temp_resolution': 60,\n",
    "    'location': pair_1[1],\n",
    "    'model': model,\n",
    "}\n",
    "\n",
    "with open(f'sweep_configurations/config_sweep_{model}.json', 'r') as fp:\n",
    "    sweep_config = json.load(fp)\n",
    "\n",
    "config_modeldesign = {'boxcox': True,\n",
    "                    'horizon_in_hours': 24, # in hours\n",
    "                    'lookback_in_hours': 24, # in hours\n",
    "                    'liklihood': None,\n",
    "                    'weather': True,\n",
    "                    'holiday': True,\n",
    "                    'datetime_encodings': True,\n",
    "                    }\n",
    "\n",
    "list_metrics = [smape, mape, r2_score, mae, rmse] # evaluation metrics                  \n",
    "\n",
    "sweep_config['name'] = model + 'sweep' + config_run['spatial_scale'] + '_' + config_run['location'] + '_' + str(config_run['temp_resolution'])\n",
    "\n",
    "\n",
    "# wandb.init(project=\"WattCast_tuning\")\n",
    "\n",
    "# config = wandb.config\n",
    "# config.update(config_run)\n",
    "# config.update(config_modeldesign)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_light():\n",
    "\n",
    "    wandb.init(project=\"WattCast_tuning\")\n",
    "    wandb.config.update(config_run)\n",
    "    wandb.config.update(config_modeldesign)\n",
    "    config = wandb.config\n",
    "\n",
    "    print(\"Getting data...\")\n",
    "\n",
    "    pipeline, ts_train_piped, ts_val_piped, ts_test_piped, ts_train_weather_piped, ts_val_weather_piped, ts_test_weather_piped, trg_train_inversed, trg_val_inversed, trg_test_inversed = data_pipeline(config)\n",
    "\n",
    "    print(\"Getting model instance...\")\n",
    "    model = get_model_instance(config)\n",
    "    model, runtime = train_models(model, ts_train_piped, ts_train_weather_piped, ts_val_piped, ts_val_weather_piped)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    predictions, score = predict_testset(model[0], \n",
    "                                  ts_test_piped[config.longest_ts_test_idx], \n",
    "                                  ts_test_weather_piped[config.longest_ts_test_idx],\n",
    "                                  config.n_lags, config.n_ahead, config.eval_stride, pipeline,\n",
    "                                  )\n",
    "\n",
    "\n",
    "    print(\"Plotting predictions...\")\n",
    "    df_compare = pd.concat([trg_test_inversed.pd_dataframe(), predictions], axis=1).dropna()\n",
    "    df_compare.columns = ['target', 'prediction']\n",
    "    fig = px.line(df_compare, title='Predictions vs. Test Set')\n",
    "\n",
    "    wandb.log({'eval_loss': score})\n",
    "    wandb.log({'predictions': fig})\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "def data_pipeline(config):\n",
    "\n",
    "    if config.temp_resolution == 60:\n",
    "        timestep_encoding = [\"hour\"] \n",
    "    elif config.temp_resolution == 15:\n",
    "        timestep_encoding = ['quarter']\n",
    "    else:\n",
    "        timestep_encoding = [\"hour\", \"minute\"]\n",
    "\n",
    "\n",
    "    datetime_encoders =  {\n",
    "                        \"cyclic\": {\"future\": timestep_encoding}, \n",
    "                        \"position\": {\"future\": [\"relative\",]},\n",
    "                        \"datetime_attribute\": {\"future\": [\"dayofweek\", \"week\"]},\n",
    "                        'position': {'past': ['relative'], 'future': ['relative']},\n",
    "                }\n",
    "\n",
    "    datetime_encoders = datetime_encoders if config.datetime_encodings else None\n",
    "\n",
    "    config['datetime_encoders'] = datetime_encoders\n",
    "\n",
    "\n",
    "    config.timesteps_per_hour = int(60 / config.temp_resolution)\n",
    "    config.n_lags = config.lookback_in_hours * config.timesteps_per_hour\n",
    "    config.n_ahead = config.horizon_in_hours * config.timesteps_per_hour\n",
    "    config.eval_stride = int(np.sqrt(config.n_ahead)) # evaluation stride, how often to evaluate the model, in this case we evaluate every n_ahead steps\n",
    "\n",
    "    # Loading Data\n",
    "    df_train = pd.read_hdf(os.path.join(dir_path, f'{config.spatial_scale}.h5'), key=f'{config.location}/{config.temp_resolution}min/train_target')\n",
    "    df_val = pd.read_hdf(os.path.join(dir_path, f'{config.spatial_scale}.h5'), key=f'{config.location}/{config.temp_resolution}min/val_target')\n",
    "    df_test = pd.read_hdf(os.path.join(dir_path, f'{config.spatial_scale}.h5'),key=f'{config.location}/{config.temp_resolution}min/test_target')\n",
    "\n",
    "    df_cov_train = pd.read_hdf(os.path.join(dir_path, f'{config.spatial_scale}.h5'), key=f'{config.location}/{config.temp_resolution}min/train_cov')\n",
    "    df_cov_val = pd.read_hdf(os.path.join(dir_path, f'{config.spatial_scale}.h5'), key=f'{config.location}/{config.temp_resolution}min/val_cov')\n",
    "    df_cov_test = pd.read_hdf(os.path.join(dir_path,f'{config.spatial_scale}.h5'), key=f'{config.location}/{config.temp_resolution}min/test_cov')\n",
    "\n",
    "    # into darts format\n",
    "    ts_train = darts.TimeSeries.from_dataframe(df_train, freq=str(config.temp_resolution) + 'min')\n",
    "    ts_train = extract_subseries(ts_train)\n",
    "    ts_val = darts.TimeSeries.from_dataframe(df_val, freq=str(config.temp_resolution) + 'min')\n",
    "    ts_val = extract_subseries(ts_val)\n",
    "    ts_test = darts.TimeSeries.from_dataframe(df_test, freq=str(config.temp_resolution) + 'min')\n",
    "    ts_test = extract_subseries(ts_test)\n",
    "\n",
    "    # Covariates\n",
    "    if config.weather:\n",
    "        ts_cov_train = darts.TimeSeries.from_dataframe(df_cov_train, freq=str(config.temp_resolution) + 'min')\n",
    "        ts_cov_val = darts.TimeSeries.from_dataframe(df_cov_val, freq=str(config.temp_resolution) + 'min')\n",
    "        ts_cov_test = darts.TimeSeries.from_dataframe(df_cov_test, freq=str(config.temp_resolution) + 'min')\n",
    "    else:\n",
    "        ts_cov_train = None\n",
    "        ts_cov_val = None\n",
    "        ts_cov_test = None\n",
    "\n",
    "    # Reviewing subseries to make sure they are long enough\n",
    "    ts_train, ts_cov_train = review_subseries(ts_train, config.n_lags + config.n_ahead, ts_cov_train)\n",
    "    ts_val, ts_cov_val = review_subseries(ts_val, config.n_lags + config.n_ahead, ts_cov_val)\n",
    "    ts_test, ts_cov_test = review_subseries(ts_test, config.n_lags +config.n_ahead, ts_cov_test)\n",
    "\n",
    "    # getting the index of the longest subseries, to be used for evaluation later\n",
    "    config.longest_ts_val_idx = get_longest_subseries_idx(ts_val)\n",
    "    config.longest_ts_test_idx = get_longest_subseries_idx(ts_test)\n",
    "\n",
    "    # Preprocessing Pipeline\n",
    "    pipeline = Pipeline( # missing values have been filled in the 'data_prep.ipynb'\n",
    "                    [\n",
    "                    BoxCox() if config.boxcox else None,\n",
    "                    Scaler(MinMaxScaler()),\n",
    "                    ]\n",
    "                    )\n",
    "    ts_train_piped = pipeline.fit_transform(ts_train)\n",
    "    ts_val_piped = pipeline.transform(ts_val)\n",
    "    ts_test_piped = pipeline.transform(ts_test)\n",
    "\n",
    "    # Weather Pipeline\n",
    "    if config.weather:\n",
    "        pipeline_weather = Pipeline([Scaler(RobustScaler())])\n",
    "        ts_train_weather_piped = pipeline_weather.fit_transform(ts_cov_train)\n",
    "        ts_val_weather_piped = pipeline_weather.transform(ts_cov_val)\n",
    "        ts_test_weather_piped = pipeline_weather.transform(ts_cov_test)\n",
    "    else:\n",
    "        ts_train_weather_piped = None\n",
    "        ts_val_weather_piped = None\n",
    "        ts_test_weather_piped = None\n",
    "\n",
    "    trg_train_inversed = pipeline.inverse_transform(ts_train_piped, partial=True) \n",
    "    trg_val_inversed = pipeline.inverse_transform(ts_val_piped, partial=True)[config.longest_ts_val_idx] \n",
    "    trg_test_inversed = pipeline.inverse_transform(ts_test_piped, partial=True)[config.longest_ts_test_idx]\n",
    "\n",
    "    return pipeline, ts_train_piped, ts_val_piped, ts_test_piped, ts_train_weather_piped, ts_val_weather_piped, ts_test_weather_piped, trg_train_inversed, trg_val_inversed, trg_test_inversed\n",
    "\n",
    "\n",
    "\n",
    "def get_model_instance(config):\n",
    "\n",
    "    model = config.model\n",
    "\n",
    "    if model == 'xgb':\n",
    "\n",
    "        try:\n",
    "            xgb_kwargs = {\n",
    "            'n_estimators': config.n_estimators,\n",
    "            'max_depth': config.max_depth,\n",
    "            'learning_rate': config.learning_rate,\n",
    "            'min_child_weight': config.min_child_weight,\n",
    "            'objective': config.objective,\n",
    "            'reg_lambda': config.reg_lambda,\n",
    "            'early_stopping_rounds': 10\n",
    "            }\n",
    "        except:\n",
    "            xgb_kwargs ={}\n",
    "\n",
    "        model = XGBModel(lags=config.n_lags,\n",
    "                            lags_future_covariates=[0],\n",
    "                            add_encoders=config.datetime_encoders, \n",
    "                            output_chunk_length=config.n_ahead, \n",
    "                            likelihood=config.liklihood,\n",
    "                            random_state=42,\n",
    "                            **xgb_kwargs\n",
    "                            )\n",
    "    \n",
    "    elif model == 'gru':\n",
    "\n",
    "        optimizer_kwargs = {}\n",
    "        optimizer_kwargs['lr'] = config.lr\n",
    "        \n",
    "        pl_trainer_kwargs = {\n",
    "        'max_epochs': 50,\n",
    "        'accelerator': 'gpu',\n",
    "        'devices': [0],\n",
    "        'callbacks': [EarlyStopping(monitor='val_loss', patience=5, mode='min')],\n",
    "        'logger': WandbLogger(log_model='all'),\n",
    "        }\n",
    "\n",
    "        schedule_kwargs = {\n",
    "            'patience': 2,\n",
    "            'factor': 0.5,\n",
    "            'min_lr': 1e-5,\n",
    "            'verbose': True\n",
    "            }\n",
    "\n",
    "        model = BlockRNNModel(  \n",
    "                        model = 'GRU',\n",
    "                        input_chunk_length=config.n_lags,\n",
    "                        output_chunk_length=config.n_ahead,\n",
    "                        hidden_dim=config.hidden_dim,\n",
    "                        n_rnn_layers=config.n_rnn_layers,\n",
    "                        batch_size=config.batch_size,\n",
    "                        dropout=config.dropout,\n",
    "                        add_encoders=config.datetime_encoders,\n",
    "                        likelihood=config.liklihood,\n",
    "                        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "                        optimizer_kwargs=optimizer_kwargs,\n",
    "                        lr_scheduler_cls=ReduceLROnPlateau,\n",
    "                        lr_scheduler_kwargs=schedule_kwargs,\n",
    "                        random_state=42,\n",
    "                    )\n",
    "\n",
    "    return [model]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweepin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"WattCast_tuning\")\n",
    "wandb.agent(sweep_id, train_eval_light, count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
