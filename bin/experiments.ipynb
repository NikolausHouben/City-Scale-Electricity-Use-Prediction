{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaushouben/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "from utils import get_hdf_keys\n",
    "from train import training\n",
    "from evaluation import evaluate, get_run_results\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/nikolaushouben/Desktop/WattCast\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\"\n",
    "dir_path = os.path.join(os.getcwd(), 'data', 'clean_data')\n",
    "model_dir = os.path.join(os.getcwd(), 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_dict, resolutions_dict = get_hdf_keys(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all locations and resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for a single location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GLENDOVEER-13596 at 2_town scale\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikolaushouben/Desktop/WattCast/wandb/run-20231005_151855-2_town_GLENDOVEER-13596_60min</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/Portland_AMI/runs/2_town_GLENDOVEER-13596_60min' target=\"_blank\">2_town_GLENDOVEER-13596_60min</a></strong> to <a href='https://wandb.ai/wattcast/Portland_AMI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/Portland_AMI' target=\"_blank\">https://wandb.ai/wattcast/Portland_AMI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/Portland_AMI/runs/2_town_GLENDOVEER-13596_60min' target=\"_blank\">https://wandb.ai/wattcast/Portland_AMI/runs/2_town_GLENDOVEER-13596_60min</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by -summary_metrics.eval_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched sweep with name pleasant-sweep-24 for model rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by -summary_metrics.eval_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched sweep with name ethereal-sweep-2 for model xgb\n",
      "Getting model instance for rf...\n",
      "Initializing kwargs for sklearn-API type model rf...\n",
      "['max_depth', 'min_samples_split', 'n_estimators', 'min_samples_leaf']\n",
      "Getting model instance for xgb...\n",
      "Initializing kwargs for sklearn-API type model xgb...\n",
      "['max_depth', 'reg_lambda', 'learning_rate', 'eval_metric', 'objective', 'early_stopping_rounds', 'min_child_weight', 'verbosity', 'n_estimators']\n",
      "Getting model instance for linear regression...\n",
      "Directory already exists: /Users/nikolaushouben/Desktop/WattCast/data/evaluations\n",
      "No existing evaluation found, running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`enable_optimization=True` is ignored because `forecast_horizon > self.output_chunk_length`.To hide this warning, set `show_warnings=False` or `enable_optimization=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Winter data\n",
      "Generating historical forecasts with RandomForest\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/WattCast/bin/evaluation.py:269\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(init_config, models_dict)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(evaluation_path, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mconfig\u001b[39m.\u001b[39;49mlocation\u001b[39m}\u001b[39;49;00m\u001b[39m.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    270\u001b[0m         dict_result_n_ahead \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nikolaushouben/Desktop/WattCast/data/evaluations/2_town/GLENDOVEER-13596.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m wandb\u001b[39m.\u001b[39minit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPortland_AMI\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39mname_id, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39mname_id\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m ) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m config, models \u001b[39m=\u001b[39m training(init_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m eval_dict \u001b[39m=\u001b[39m evaluate(config, models)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m df_metrics \u001b[39m=\u001b[39m get_run_results(eval_dict, config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikolaushouben/Desktop/WattCast/bin/experiments.ipynb#X25sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/Desktop/WattCast/bin/evaluation.py:313\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(init_config, models_dict)\u001b[0m\n\u001b[1;32m    294\u001b[0m longest_ts_test_idx \u001b[39m=\u001b[39m get_longest_subseries_idx(ts_test_piped)\n\u001b[1;32m    296\u001b[0m test_sets \u001b[39m=\u001b[39m {  \u001b[39m# see data_prep.ipynb for the split\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWinter\u001b[39m\u001b[39m\"\u001b[39m: (\n\u001b[1;32m    298\u001b[0m         ts_val_piped[longest_ts_val_idx],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m     ),\n\u001b[1;32m    311\u001b[0m }\n\u001b[0;32m--> 313\u001b[0m dict_result_season \u001b[39m=\u001b[39m backtesting(models_dict, pipeline, test_sets, config)\n\u001b[1;32m    314\u001b[0m dict_result_n_ahead \u001b[39m=\u001b[39m extract_forecasts_per_horizon(config, dict_result_season)\n\u001b[1;32m    316\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(evaluation_path, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mlocation\u001b[39m}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/WattCast/bin/evaluation.py:337\u001b[0m, in \u001b[0;36mbacktesting\u001b[0;34m(models_dict, pipeline, test_sets, config)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    336\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating historical forecasts with \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 337\u001b[0m     historics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mhistorical_forecasts(\n\u001b[1;32m    338\u001b[0m         ts,\n\u001b[1;32m    339\u001b[0m         future_covariates\u001b[39m=\u001b[39;49mts_cov \u001b[39mif\u001b[39;49;00m model\u001b[39m.\u001b[39;49msupports_future_covariates \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    340\u001b[0m         start\u001b[39m=\u001b[39;49mts\u001b[39m.\u001b[39;49mget_index_at_point(config\u001b[39m.\u001b[39;49mn_lags),\n\u001b[1;32m    341\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    342\u001b[0m         stride\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,  \u001b[39m# this allows us to later differentiate between the different horizons\u001b[39;49;00m\n\u001b[1;32m    343\u001b[0m         forecast_horizon\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mtimesteps_per_hour\n\u001b[1;32m    344\u001b[0m         \u001b[39m*\u001b[39;49m \u001b[39m48\u001b[39;49m,  \u001b[39m# 48 hours is our max horizon\u001b[39;49;00m\n\u001b[1;32m    345\u001b[0m         retrain\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    346\u001b[0m         last_points_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     historics_inverted \u001b[39m=\u001b[39m [\n\u001b[1;32m    350\u001b[0m         pipeline\u001b[39m.\u001b[39minverse_transform(historic) \u001b[39mfor\u001b[39;00m historic \u001b[39min\u001b[39;00m historics\n\u001b[1;32m    351\u001b[0m     ][\n\u001b[1;32m    352\u001b[0m         \u001b[39m1\u001b[39m:\n\u001b[1;32m    353\u001b[0m     ]  \u001b[39m# the first historic is partly nan, so we skip it\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     historics_per_model[\n\u001b[1;32m    355\u001b[0m         model_name\n\u001b[1;32m    356\u001b[0m     ] \u001b[39m=\u001b[39m historics_inverted  \u001b[39m# storing the forecasts in batches of the forecasting horizon, for plot 2\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/darts/utils/utils.py:177\u001b[0m, in \u001b[0;36m_with_sanity_checks.<locals>.decorator.<locals>.sanitized_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     only_args\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, sanity_check_method)(\u001b[39m*\u001b[39monly_args\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39monly_kwargs)\n\u001b[0;32m--> 177\u001b[0m \u001b[39mreturn\u001b[39;00m method_to_sanitize(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49monly_args\u001b[39m.\u001b[39;49mvalues(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49monly_kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/darts/models/forecasting/forecasting_model.py:896\u001b[0m, in \u001b[0;36mForecastingModel.historical_forecasts\u001b[0;34m(self, series, past_covariates, future_covariates, num_samples, train_length, start, forecast_horizon, stride, retrain, overlap_end, last_points_only, verbose, show_warnings, predict_likelihood_parameters, enable_optimization)\u001b[0m\n\u001b[1;32m    888\u001b[0m historical_forecasts_time_index \u001b[39m=\u001b[39m generate_index(\n\u001b[1;32m    889\u001b[0m     start\u001b[39m=\u001b[39mhistorical_forecasts_time_index[\u001b[39m0\u001b[39m],\n\u001b[1;32m    890\u001b[0m     end\u001b[39m=\u001b[39mhistorical_forecasts_time_index[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    891\u001b[0m     freq\u001b[39m=\u001b[39mseries_\u001b[39m.\u001b[39mfreq,\n\u001b[1;32m    892\u001b[0m )\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(series) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    895\u001b[0m     \u001b[39m# Only use tqdm if there's no outer loop\u001b[39;00m\n\u001b[0;32m--> 896\u001b[0m     iterator \u001b[39m=\u001b[39m _build_tqdm_iterator(\n\u001b[1;32m    897\u001b[0m         historical_forecasts_time_index[::stride], verbose\n\u001b[1;32m    898\u001b[0m     )\n\u001b[1;32m    899\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     iterator \u001b[39m=\u001b[39m historical_forecasts_time_index[::stride]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/darts/utils/utils.py:109\u001b[0m, in \u001b[0;36m_build_tqdm_iterator\u001b[0;34m(iterable, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m _isnotebook():\n\u001b[0;32m--> 109\u001b[0m         iterator \u001b[39m=\u001b[39m tqdm_notebook(iterable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    110\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         iterator \u001b[39m=\u001b[39m tqdm(iterable, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/tqdm/notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    237\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[0;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[1;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/tqdm/notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[1;32m    115\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "scale = '2_town'\n",
    "location = 'GLENDOVEER-13596'\n",
    "\n",
    "print(f\"Training {location} at {scale} scale\")\n",
    "\n",
    "init_config = {\n",
    "    'spatial_scale': \"2_town\",\n",
    "    'temp_resolution': 60,\n",
    "    'location': 'GLENDOVEER-13596',\n",
    "    'models_to_train': [\"rf\", \"xgb\"],\n",
    "    'horizon_in_hours': 24,\n",
    "    'lookback_in_hours': 24,\n",
    "    'boxcox': True,\n",
    "    'liklihood': None,\n",
    "    'weather_available': True,\n",
    "    'datetime_encodings': True,\n",
    "    'heat_wave_binary': True,\n",
    "    'datetime_attributes': [\"dayofweek\", \"week\"],\n",
    "    'use_cov_as_past_cov': False,\n",
    "}\n",
    "\n",
    "name_id = (\n",
    "    init_config[\"spatial_scale\"]\n",
    "    + \"_\"\n",
    "    + init_config[\"location\"]\n",
    "    + \"_\"\n",
    "    + str(init_config[\"temp_resolution\"])\n",
    "    + \"min\"\n",
    ")\n",
    "wandb.init(\n",
    "    project=\"Portland_AMI\", name=name_id, id=name_id\n",
    ") \n",
    "\n",
    "config, models = training(init_config)\n",
    "\n",
    "eval_dict = evaluate(config, models)\n",
    "\n",
    "df_metrics = get_run_results(eval_dict, config)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
