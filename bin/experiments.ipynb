{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "from utils import get_hdf_keys\n",
    "from train import training\n",
    "from evaluation import evaluate, get_run_results\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\"\n",
    "dir_path = os.path.join(os.getcwd(), 'data', 'clean_data')\n",
    "model_dir = os.path.join(os.getcwd(), 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_dict, resolutions_dict = get_hdf_keys(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2_town.h5': ['GLENDOVEER-13596',\n",
       "  'GLENDOVEER-13597',\n",
       "  'GLENDOVEER-13598',\n",
       "  'GLENDOVEER-13599',\n",
       "  'GLENDOVEER-CLIFFGATE',\n",
       "  'GLENDOVEER-NORTHEAST',\n",
       "  'KELLY',\n",
       "  'LENTS-13101',\n",
       "  'LENTS-HAPPY',\n",
       "  'LENTS-MT',\n",
       "  'LENTS-NORTH',\n",
       "  'MIDWAY-DIVISION',\n",
       "  'MIDWAY-DOUGLAS',\n",
       "  'MIDWAY-LYNCH',\n",
       "  'MIDWAY-POWELLHURST',\n",
       "  'RAMAPO-EMERALD',\n",
       "  'RAMAPO-GILBERT',\n",
       "  'RAMAPO-RAMAPO']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all locations and resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale, locations in locations_dict.items():\n",
    "\n",
    "    scale = scale.split('.')[0]\n",
    "    for location in locations:\n",
    "\n",
    "        print(f\"Training {location} at {scale} scale\")\n",
    "        config, models = training(scale, location, tuned_models=['xgb']) # loads existing models (from disk) if they exist, otherwise trains new models with optimial hyperparameters (from wandb) if they exist\n",
    "        eval_dict = evaluate(config, models) # loads existing run results (from wandb) if they exist, otherwise runs a backtest for each model on the val and test set, and then formats it into the various horizons\n",
    "        df_metrics = get_run_results(eval_dict, config) # calculates the error scores and produces plots, logging them to wandb if possible\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for a single location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GLENDOVEER-13596 at 2_town scale\n",
      "Could not find a sweep for model tide and scale 2_town in project Wattcast_tuning.\n",
      "Fetched sweep with name None for model tide\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c1ae301e4b4e84aee6185fb2f4fb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\\wandb\\run-20231004_232017-2_town_GLENDOVEER-13596_60min</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/Portland_AMI/runs/2_town_GLENDOVEER-13596_60min' target=\"_blank\">2_town_GLENDOVEER-13596_60min</a></strong> to <a href='https://wandb.ai/wattcast/Portland_AMI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/Portland_AMI' target=\"_blank\">https://wandb.ai/wattcast/Portland_AMI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/Portland_AMI/runs/2_town_GLENDOVEER-13596_60min' target=\"_blank\">https://wandb.ai/wattcast/Portland_AMI/runs/2_town_GLENDOVEER-13596_60min</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'temp_resolution'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\\bin\\experiments.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nik/Desktop/Berkeley_Projects/WattCast/bin/experiments.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m location \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mGLENDOVEER-13596\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nik/Desktop/Berkeley_Projects/WattCast/bin/experiments.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m at \u001b[39m\u001b[39m{\u001b[39;00mscale\u001b[39m}\u001b[39;00m\u001b[39m scale\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nik/Desktop/Berkeley_Projects/WattCast/bin/experiments.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m config, models \u001b[39m=\u001b[39m training(scale, location, tuned_models\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtide\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nik/Desktop/Berkeley_Projects/WattCast/bin/experiments.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m eval_dict \u001b[39m=\u001b[39m evaluate(config, models)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nik/Desktop/Berkeley_Projects/WattCast/bin/experiments.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_metrics \u001b[39m=\u001b[39m get_run_results(eval_dict, config)\n",
      "File \u001b[1;32mc:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\\bin\\train.py:596\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(scale, location, tuned_models)\u001b[0m\n\u001b[0;32m    581\u001b[0m wandb\u001b[39m.\u001b[39minit(project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPortland_AMI\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39mname_id, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39mname_id)\n\u001b[0;32m    583\u001b[0m config \u001b[39m=\u001b[39m Config()\u001b[39m.\u001b[39mfrom_dict(config_per_model[tuned_models[\u001b[39m0\u001b[39m]][\u001b[39m0\u001b[39m])\n\u001b[0;32m    585\u001b[0m (\n\u001b[0;32m    586\u001b[0m     pipeline,\n\u001b[0;32m    587\u001b[0m     ts_train_piped,\n\u001b[0;32m    588\u001b[0m     ts_val_piped,\n\u001b[0;32m    589\u001b[0m     ts_test_piped,\n\u001b[0;32m    590\u001b[0m     ts_train_weather_piped,\n\u001b[0;32m    591\u001b[0m     ts_val_weather_piped,\n\u001b[0;32m    592\u001b[0m     ts_test_weather_piped,\n\u001b[0;32m    593\u001b[0m     trg_train_inversed,\n\u001b[0;32m    594\u001b[0m     trg_val_inversed,\n\u001b[0;32m    595\u001b[0m     trg_test_inersed,\n\u001b[1;32m--> 596\u001b[0m ) \u001b[39m=\u001b[39m data_pipeline(config)\n\u001b[0;32m    598\u001b[0m model_instances \u001b[39m=\u001b[39m get_model_instances(tuned_models, config_per_model)\n\u001b[0;32m    600\u001b[0m trained_models, model_instances \u001b[39m=\u001b[39m load_trained_models(config, model_instances)\n",
      "File \u001b[1;32mc:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\\bin\\train.py:346\u001b[0m, in \u001b[0;36mdata_pipeline\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_pipeline\u001b[39m(config):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39;49mtemp_resolution \u001b[39m==\u001b[39m \u001b[39m60\u001b[39m:\n\u001b[0;32m    347\u001b[0m         timestep_encoding \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    348\u001b[0m     \u001b[39melif\u001b[39;00m config\u001b[39m.\u001b[39mtemp_resolution \u001b[39m==\u001b[39m \u001b[39m15\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nik\\Desktop\\Berkeley_Projects\\WattCast\\bin\\train.py:63\u001b[0m, in \u001b[0;36mConfig.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[key]\n\u001b[0;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mConfig\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Config' object has no attribute 'temp_resolution'"
     ]
    }
   ],
   "source": [
    "scale = '2_town'\n",
    "location = 'GLENDOVEER-13596'\n",
    "\n",
    "print(f\"Training {location} at {scale} scale\")\n",
    "\n",
    "config_run = {\n",
    "    'spatial_scale': scale,\n",
    "    'temp_resolution': 60,\n",
    "    'location': location,\n",
    "    'tuned_models': ['tide'],\n",
    "    'horizon_in_hours': 24,\n",
    "    'lookback_in_hours': 24,\n",
    "    'boxcox': True,\n",
    "    'liklihood': None,\n",
    "    'weather_available': True,\n",
    "    'datetime_encodings': True,\n",
    "    'heat_wave_binary': True,\n",
    "}\n",
    "\n",
    "config, models = training(config_run)\n",
    "\n",
    "eval_dict = evaluate(config, models)\n",
    "\n",
    "df_metrics = get_run_results(eval_dict, config)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
