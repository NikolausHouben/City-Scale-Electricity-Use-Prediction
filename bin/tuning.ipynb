{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaushouben/opt/anaconda3/envs/Wattcast/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/nikolaushouben/Desktop/WattCast\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from utils import *\n",
    "from train import *\n",
    "from evaluation import *\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\"\n",
    "dir_path = os.path.join(os.getcwd(), 'data', 'clean_data')\n",
    "model_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_tuning():\n",
    "\n",
    "    wandb.init(project=\"WattCast_tuning\")\n",
    "    wandb.config.update(config_run)\n",
    "    config = wandb.config\n",
    "\n",
    "    print(\"Getting data...\")\n",
    "\n",
    "    pipeline, ts_train_piped, ts_val_piped, ts_test_piped, ts_train_weather_piped, ts_val_weather_piped, ts_test_weather_piped, trg_train_inversed, trg_val_inversed, trg_test_inversed = data_pipeline(config)\n",
    "\n",
    "    print(\"Getting model instance...\")\n",
    "    model_instance = get_model(config)\n",
    "    model_instance, _ = train_models([model_instance], ts_train_piped, ts_train_weather_piped, ts_val_piped, ts_val_weather_piped)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    predictions, score = predict_testset(model_instance[0], \n",
    "                                  ts_test_piped[config.longest_ts_test_idx], \n",
    "                                  ts_test_weather_piped[config.longest_ts_test_idx],\n",
    "                                  config.n_lags, config.n_ahead, config.eval_stride, pipeline,\n",
    "                                  )\n",
    "\n",
    "\n",
    "    print(\"Plotting predictions...\")\n",
    "    df_compare = pd.concat([trg_test_inversed.pd_dataframe(), predictions], axis=1).dropna()\n",
    "    df_compare.columns = ['target', 'prediction']\n",
    "    fig = px.line(df_compare, title='Predictions vs. Test Set')\n",
    "\n",
    "    wandb.log({'eval_loss': score})\n",
    "    wandb.log({'predictions': fig})\n",
    "    wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: yoi3jsof\n",
      "Sweep URL: https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uuku2864 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdatetime_encodings: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theat_wave_binary: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_widths: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_blocks: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_stacks: 50\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikolaushouben/Desktop/WattCast/wandb/run-20230923_155846-uuku2864</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/Wattcast_tuning/runs/uuku2864' target=\"_blank\">fallen-sweep-1</a></strong> to <a href='https://wandb.ai/wattcast/Wattcast_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/Wattcast_tuning' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/Wattcast_tuning/runs/uuku2864' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/runs/uuku2864</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'datetime_encodings' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'heat_wave_binary' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model instance...\n",
      "Training NBEATSModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-sweep-1</strong> at: <a href='https://wandb.ai/wattcast/Wattcast_tuning/runs/uuku2864' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/runs/uuku2864</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230923_155846-uuku2864/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run uuku2864 errored: MisconfigurationException('No supported gpu backend found!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run uuku2864 errored: MisconfigurationException('No supported gpu backend found!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r7en4il1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdatetime_encodings: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theat_wave_binary: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_widths: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_blocks: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_stacks: 40\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikolaushouben/Desktop/WattCast/wandb/run-20230923_155920-r7en4il1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/Wattcast_tuning/runs/r7en4il1' target=\"_blank\">cerulean-sweep-2</a></strong> to <a href='https://wandb.ai/wattcast/Wattcast_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/Wattcast_tuning' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/sweeps/yoi3jsof</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/Wattcast_tuning/runs/r7en4il1' target=\"_blank\">https://wandb.ai/wattcast/Wattcast_tuning/runs/r7en4il1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'datetime_encodings' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'heat_wave_binary' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model instance...\n",
      "Training NBEATSModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Specified future encoders in `add_encoders` at model creation but model does not accept future covariates. future encoders will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we keep the number of sweeps constant to ensure a fair playing field for all algorithms\n",
    "sweeps = 3 # number of sweeps per model, per location: \n",
    "\n",
    "scale_location_pairs = (\n",
    "     ('1_county', 'Sacramento'),\n",
    "    ('1_county', 'New_York'),\n",
    "    #('1_county', 'Los_Angeles'),\n",
    "    ('2_town', 'town_0'),\n",
    "     ('2_town', 'town_1'),\n",
    "     ('2_town', 'town_2'),\n",
    "     ('3_village', 'village_1'),\n",
    "     ('3_village', 'village_2'),\n",
    "    ('3_village', 'village_0'),\n",
    "    ('4_neighborhood', 'neighborhood_0'),\n",
    "     ('4_neighborhood', 'neighborhood_1'),\n",
    "     ('4_neighborhood', 'neighborhood_2'),\n",
    "    ('5_building', 'building_0'),\n",
    "    ('5_building', 'building_1'),\n",
    "    ('5_building', 'building_2'),\n",
    "      )\n",
    "\n",
    "scale_location_pairs = (\n",
    "     ('1_county', 'Sacramento'),\n",
    ")\n",
    "\n",
    "models = [\n",
    "        #'rf',\n",
    "        #'xgb', \n",
    "        #'gru', \n",
    "        #'lgbm',  \n",
    "        'nbeats',\n",
    "        #'tft'\n",
    "        ]\n",
    "\n",
    "\n",
    "for scale, location in scale_location_pairs:\n",
    "\n",
    "    for model in models:\n",
    "        # placeholder initialization of config file (will be updated in train_eval_light())\n",
    "        config_run = {\n",
    "            'spatial_scale': scale,\n",
    "            'temp_resolution': 60,\n",
    "            'location': location,\n",
    "            'model': model,\n",
    "            'horizon_in_hours': 24,\n",
    "            'lookback_in_hours': 24,\n",
    "            'boxcox': True,\n",
    "            'liklihood': None,\n",
    "            'weather': True,\n",
    "            'holiday': True,\n",
    "            'datetime_encodings': False,\n",
    "            'heat_wave_binary': False,\n",
    "        }\n",
    "        \n",
    "        with open(f'sweep_configurations/config_sweep_{model}.json', 'r') as fp:\n",
    "            sweep_config = json.load(fp)                  \n",
    "\n",
    "        sweep_config['name'] = model + 'sweep' + config_run['spatial_scale'] + '_' + config_run['location'] + '_' + str(config_run['temp_resolution'])\n",
    "\n",
    "        sweep_id = wandb.sweep(sweep_config, project=\"WattCast_tuning\")\n",
    "        wandb.agent(sweep_id, train_eval_tuning, count=sweeps)\n",
    "        wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degbugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_run = {\n",
    "    'spatial_scale': '1_county',\n",
    "    'temp_resolution': 60,\n",
    "    'location': 'Los_Angeles',\n",
    "    'model': 'tft',\n",
    "    'horizon_in_hours': 24,\n",
    "    'lookback_in_hours': 24,\n",
    "    'boxcox': True,\n",
    "    'liklihood': None,\n",
    "    'weather': True,\n",
    "    'holiday': True,\n",
    "    'datetime_encodings': False,\n",
    "    'heat_wave_binary': False,\n",
    "}\n",
    "\n",
    "wandb.init(project=\"WattCast_tuning\")\n",
    "wandb.config.update(config_run)\n",
    "config = wandb.config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "config = config.from_dict(config_run)\n",
    "\n",
    "\n",
    "with open(f'sweep_configurations/config_sweep_{config.model}.json', 'r') as fp:\n",
    "            sweep_config = json.load(fp)   \n",
    "\n",
    "hypers = {param: values['values'][0] for param, values in sweep_config['parameters'].items()}\n",
    "\n",
    "for param, value in hypers.items():\n",
    "    setattr(config, param, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, ts_train_piped, ts_val_piped, ts_test_piped, ts_train_weather_piped, ts_val_weather_piped, ts_test_weather_piped, trg_train_inversed, trg_val_inversed, trg_test_inversed = data_pipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
