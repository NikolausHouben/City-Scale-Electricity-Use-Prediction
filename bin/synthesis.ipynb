{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "The `Prophet` module could not be imported. To enable Prophet support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "The `CatBoost` module could not be imported. To enable CatBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# set font to 12 and times new roman\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/nikolaushouben/Desktop/WattCast\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(r\"..\") # should be the git repo root directory, checking below:\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "assert os.getcwd()[-8:] == \"WattCast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikolaushouben/Desktop/WattCast/wandb/run-20230830_145705-results_synthesis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wattcast/Wattcast/runs/results_synthesis' target=\"_blank\">results_synthesis</a></strong> to <a href='https://wandb.ai/wattcast/Wattcast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/Wattcast' target=\"_blank\">https://wandb.ai/wattcast/Wattcast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/Wattcast/runs/results_synthesis' target=\"_blank\">https://wandb.ai/wattcast/Wattcast/runs/results_synthesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Wattcast', name='results_synthesis', id = 'results_synthesis', resume=True)\n",
    "\n",
    "project_name = \"Wattcast\"\n",
    "# Initialize your project\n",
    "api = wandb.Api()\n",
    "runs = api.runs(project_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing all metrics from all runs from wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_run_name_id_dict(runs):\n",
    "    '''Loops through all runs and returns a dictionary of run names and ids'''\n",
    "    name_id_dict = {}\n",
    "    for run_ in runs:\n",
    "        l = run_.name.split('_')[:-1]\n",
    "        l.insert(2, 'in')\n",
    "        n = '_'.join(l)\n",
    "        # remove the _ around in\n",
    "        n = n.replace('_in_', 'in')\n",
    "        name_id_dict[n] = run_.id\n",
    "    return name_id_dict\n",
    "\n",
    "\n",
    "name_id_dict = get_run_name_id_dict(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results_in': 'results_synthesis',\n",
       " '3_villageinvillage_2': '3_village_village_2_60min',\n",
       " '3_villageinvillage_1': '3_village_village_1_60min',\n",
       " '3_villageinvillage_0': '3_village_village_0_60min',\n",
       " '2_townintown_2': '2_town_town_2_60min',\n",
       " '2_townintown_1': '2_town_town_1_60min',\n",
       " '2_townintown_0': '2_town_town_0_60min',\n",
       " '1_countyinSacramento': '1_county_Sacramento_60min',\n",
       " '1_countyinNew_York': '1_county_New_York_60min',\n",
       " '1_countyinLos_Angeles': '1_county_Los_Angeles_60min',\n",
       " '4_neighborhoodingermany': '4_neighborhood_germany_60min'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_id_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figures & Tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings for plotting shapes and colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2shape = {\n",
    "    'RandomForest': 'o',\n",
    "    'LightGBMModel': 's',\n",
    "    'XGBModel': 'D',\n",
    "    'BlockRNNModel': 'x',\n",
    "    'NBEATSModel': '^',\n",
    "    'TFTModel': 'v',\n",
    "    'LinearRegressionModel': '*',\n",
    "    '48-Hour Persistence': 'P'\n",
    "}\n",
    "\n",
    "\n",
    "model2color = {\n",
    "    'RandomForest': 'blue',\n",
    "    'LightGBMModel': 'orange',\n",
    "    'XGBModel': 'green',\n",
    "    'BlockRNNModel': 'red',\n",
    "    'NBEATSModel': 'purple',\n",
    "    'TFTModel': 'pink',\n",
    "    'LinearRegressionModel': 'brown',\n",
    "    '48-Hour Persistence': 'black'\n",
    "}\n",
    "\n",
    "\n",
    "shape2model = {v: k for k, v in model2shape.items()}\n",
    "\n",
    "\n",
    "metric_dict = {'mape': 'Mean Absolute Percentage Error (MAPE)',\n",
    "               'rmse': 'Root Mean Squared Error (RMSE)',\n",
    "                'mae': 'Mean Absolute Error (MAE)',\n",
    "                'smape': 'Symmetric Mean Absolute Percentage Error (SMAPE)',\n",
    "                'rmse_skill_score': 'RMSE Skill Score',\n",
    "                'r2_score': 'R2 Score',\n",
    "                'max_peak_error': 'Max Peak Error',\n",
    "                'mean_n_peak_error': 'Mean N Peak Error',\n",
    "                }\n",
    "\n",
    "season2color = {'Summer': 'orange', 'Winter': 'blue'}\n",
    "color2season = {v: k for k, v in season2color.items()}\n",
    "\n",
    "horizon2color = {'Ground Truth': 'black',\n",
    "                '1 Hours Ahead': 'blue',\n",
    "                '4 Hours Ahead': 'green',\n",
    "                '8 Hours Ahead': 'orange',\n",
    "                '24 Hours Ahead': 'red',\n",
    "                '48 Hours Ahead': 'purple'}\n",
    "\n",
    "\n",
    "model_groups = {'Tree-based': ['RandomForest', 'LightGBMModel', 'XGBModel'],\n",
    "                         'Neural Network': ['BlockRNNModel', 'NBEATSModel', 'TFTModel'],}\n",
    "\n",
    "model2group = {}\n",
    "for group, models in model_groups.items():\n",
    "    for model in models:\n",
    "        model2group[model] = group\n",
    "\n",
    "\n",
    "group2shape = {'Tree-based': 'x', 'Neural Network': 'o'}\n",
    "shape2group = {v: k for k, v in group2shape.items()}\n",
    "\n",
    "group2color = {'Tree-based': 'blue', 'Neural Network': 'red'}\n",
    "color2group = {v: k for k, v in group2color.items()}\n",
    "\n",
    "\n",
    "scale2unit = {'county': 'GW', 'town': 'MW', 'village': 'kW', 'neighborhood': 'kW'}\n",
    "unit2kWh = {'W':1/1000, 'kW': 1, 'MW': 1000, 'GW': 1000000}\n",
    "\n",
    "\n",
    "index2county_locations = {0: 'Los_Angeles', 1: 'New_York', 2: 'Sacramento'}\n",
    "index2town_locations = {0: 'town_0', 1: 'town_1', 2: 'town_2'}\n",
    "index2village_locations = {0: 'village_0', 1: 'village_1', 2: 'village_2'}\n",
    "index2neighborhood_locations = {0: 'neighborhood_0', 1: 'neighborhood_1', 2: 'neighborhood_2'}\n",
    "scale2ordering = {'county': index2county_locations, 'town': index2town_locations, 'village': index2village_locations, 'neighborhood': index2neighborhood_locations}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing error metric tables (used in most sections below)\n",
    "key_list = list(name_id_dict.keys())\n",
    "for key in key_list:\n",
    "    if key[0] not in ['1', '2', '3', '4', '5']:\n",
    "        del name_id_dict[key]\n",
    "        \n",
    "dfs_sorted = {}\n",
    "for name, id in name_id_dict.items():\n",
    "    try:\n",
    "        run_path = f'wattcast/{project_name}/run-{id}-Errormetrics:latest'\n",
    "        artifact = run.use_artifact(f'{run_path}', type='run_table')\n",
    "        artifact_dir = artifact.download()\n",
    "        with open(os.path.join(artifact_dir, os.listdir(artifact_dir)[0])) as f:\n",
    "            data = json.load(f)\n",
    "        df_metrics = pd.DataFrame(data['data'], columns=data['columns'])\n",
    "        df = df_metrics.sort_values(by=['model', 'season'])\n",
    "        dfs_sorted[name] = df\n",
    "    except:\n",
    "        print(f'Error in {name}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1: Skill Score vs Horizon for each model and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these:\n",
    "\n",
    "spatial_scale = 'town'\n",
    "metric_of_interest = 'rmse_skill_score'\n",
    "\n",
    "\n",
    "dfs_sorted_plot = dfs_sorted.copy()\n",
    "keys = list(dfs_sorted_plot.keys())\n",
    "for key in keys:\n",
    "    if not spatial_scale in key:\n",
    "        del dfs_sorted_plot[key]\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(dfs_sorted_plot), figsize=(5*(len(dfs_sorted_plot)),5), sharex=True, sharey=True)\n",
    "\n",
    "    \n",
    "axs = axs.ravel()\n",
    "\n",
    "# Create a list to store the handles and labels for the legend\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    # Map the colors and shapes to the DataFrame\n",
    "    name, df = list(dfs_sorted_plot.items())[i]\n",
    "    df['color'] = df['season'].map(season2color)\n",
    "    df['shape'] = df['model'].map(model2shape)\n",
    "\n",
    "    # exclude 24 hour persistence\n",
    "    df = df.loc[ df['model'] != '48-Hour Persistence']\n",
    "    \n",
    "    for shape in set(df['shape']):\n",
    "        for color in set(df.loc[df['shape'] == shape, 'color']):\n",
    "            x = df.loc[(df['shape'] == shape) & (df['color'] == color), 'horizon_in_hours']\n",
    "            y = df.loc[(df['shape'] == shape) & (df['color'] == color), metric_of_interest]\n",
    "            label = f'{shape2model[shape]} ({color2season[color]})'\n",
    "            scatter = ax.scatter(x, y, c=color, marker=shape, label=label)\n",
    "            if label not in legend_labels:\n",
    "                legend_handles.append(scatter)\n",
    "                legend_labels.append(label)\n",
    "\n",
    "    # Set the x ticks and labels\n",
    "    ax.set_xticks([1, 4, 8, 24, 48])\n",
    "    ax.set_xlabel('Forecast Horizon (hours)')\n",
    "\n",
    "    # Set the y label\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(f'{metric_dict[metric_of_interest]}')\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    ax.set_title(f'{name.split(\"in\")[-1].replace(\"_\", \" \")}')\n",
    "\n",
    "    # Add grid for each subplot\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add a horizontal red dashed line at y = 0\n",
    "    if metric_of_interest == 'rmse_skill_score':\n",
    "        ax.axhline(y=0, color='red', linestyle='--')\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "fig.legend(handles=legend_handles, labels=legend_labels, title='Model', loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=5, frameon=True)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for format in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(os.getcwd(),'imgs','figures',f'{spatial_scale}{metric_of_interest}.{format}'), bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 2: Side by side comparison of models for each season for a selected week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these\n",
    "run_to_visualize = '4_neighborhoodingermany'\n",
    "season = 'Summer'\n",
    "algorithm = 'XGBModel'\n",
    "\n",
    "\n",
    "scale = run_to_visualize.split('_')[1].split('in')[0]\n",
    "unit = scale2unit[scale]\n",
    "conversion = unit2kWh[unit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_file_names(project_name, name_id_dict, run_to_visualize, season)\n",
    "\n",
    "side_by_side_plots_dict= download_plotly_plots(get_latest_plotly_plots(files))\n",
    "\n",
    "df_all = side_by_side_df(side_by_side_plots_dict)\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the day with the highest peak\n",
    "dt_highest_peak = pd.Timestamp(df_all['Ground Truth'].idxmax()).date()\n",
    "dt_start = dt_highest_peak - pd.Timedelta(days=2)\n",
    "dt_end = dt_highest_peak + pd.Timedelta(days=2)\n",
    "\n",
    "df_all.index = pd.to_datetime(df_all.index)\n",
    "df_all = df_all.loc[dt_start:dt_end]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "df_preds = df_all.filter(like=algorithm)\n",
    "df_preds.columns = [col.split(':')[-1][1:] + ' Ahead' for col in df_preds.columns]\n",
    "df_gt = df_all.filter(like='Ground')\n",
    "df_plot = pd.concat([df_gt, df_preds], axis=1)\n",
    "for col in df_plot.columns:\n",
    "    ax.plot(df_plot[col], label=col, color=horizon2color[col], linestyle= 'solid' if col == 'Ground Truth' else ':')\n",
    "\n",
    "ax.set_ylabel(f'Electricity Load ({unit})')\n",
    "ax.set_title(f'Ground Truth and {algorithm} Predictions for {run_to_visualize}')\n",
    "\n",
    "ax.grid(True, axis='x')\n",
    "ax.legend(frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for format in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(os.getcwd(),'imgs','figures',f'plot_3_side-by-side_horizons_heat_wave_{run_to_visualize}_{season}_{algorithm}.{format}'), bbox_inches='tight')\n",
    "\n",
    "#wandb.log({f'plot_3_side-by-side_horizons_heat_wave_{run_to_visualize}_{season}_{algorithm}': wandb.Image(fig)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 3: Comparing Spatial Scales (mean of seasons and datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_of_interest = 'rmse'\n",
    "\n",
    "df_metrics_all_scales = pd.DataFrame()\n",
    "\n",
    "for scale, df in dfs_sorted.items():\n",
    "    scale = scale.split('in')[0]\n",
    "    df['scale'] = scale\n",
    "    df_metrics_all_scales = df_metrics_all_scales.append(df)\n",
    "\n",
    "# marginalize over the season\n",
    "df_metrics_grouped = df_metrics_all_scales.groupby(['scale', 'model', 'horizon_in_hours']).mean()[[metric_of_interest]].reset_index()\n",
    "\n",
    "# extract the model with the best performance for each scale and horizon\n",
    "df_metrics_grouped = df_metrics_grouped.sort_values(by=['scale', metric_of_interest], ascending=False if metric_of_interest == 'rmse_skill_score' else True)\n",
    "df_metrics_grouped = df_metrics_grouped.drop_duplicates(subset=['scale', 'horizon_in_hours'], keep='first')\n",
    "df_metrics_grouped = df_metrics_grouped.sort_values(by=['scale', 'horizon_in_hours'])\n",
    "df_metrics_grouped = df_metrics_grouped.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Define colors and shapes based on the season and model\n",
    "df = df_metrics_grouped\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the handles and labels for the legend\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "\n",
    "# Map the colors and shapes to the DataFrame\n",
    "df['shape'] = df['model'].map(model2shape)\n",
    "\n",
    "\n",
    "for scale, df_scale in df.groupby('scale'): # this for loop is to make sure the order of scales is from county to neighborhood\n",
    "    for shape in set(df_scale['shape']):\n",
    "        x = df_scale.loc[(df_scale['shape'] == shape), 'horizon_in_hours']\n",
    "        y = df_scale.loc[(df_scale['shape'] == shape), 'scale']\n",
    "        label = f'{shape2model[shape]}'\n",
    "        scatter = ax.scatter(x, y, marker=shape, label=label, color=model2color[shape2model[shape]])\n",
    "        if label not in legend_labels:\n",
    "            legend_handles.append(scatter)\n",
    "            legend_labels.append(label)\n",
    "\n",
    "# Set the x ticks and labels\n",
    "ax.set_xticks([1, 4, 8, 24, 48])\n",
    "ax.set_xlabel('Forecast Horizon (hours)')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Spatial Scale')\n",
    "\n",
    "# Set the title for each subplot\n",
    "fig.suptitle(f'Best Model by {metric_dict[metric_of_interest]}')\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "fig.legend(handles=legend_handles, labels=legend_labels, title='Model', loc='lower center', bbox_to_anchor=(0.6, -0.25), ncol=2, frameon=True)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for format in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(os.getcwd(),'imgs','figures',f'plot_1_overview_across_scales_{metric_of_interest}.{format}'), bbox_inches='tight')\n",
    "\n",
    "#wandb.log({f'plot_1_overview_across_scales_{metric_of_interest}': fig})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 4: Comparing Spatial Scales (mean of datasets per season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_all_scales = pd.DataFrame()\n",
    "\n",
    "for scale, df in dfs_sorted.items():\n",
    "    scale = scale.split('in')[0]\n",
    "    df['scale'] = scale\n",
    "    df_metrics_all_scales = df_metrics_all_scales.append(df)\n",
    "\n",
    "df_metrics_grouped = df_metrics_all_scales.groupby(['season', 'scale', 'model', 'horizon_in_hours']).mean()[[metric_of_interest]].reset_index()\n",
    "\n",
    "season = 'Winter'\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,5), sharex=True, sharey=True)\n",
    "\n",
    "axs = axs.ravel()\n",
    "# Create a list to store the handles and labels for the legend\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "\n",
    "    season = list(season2color.keys())[i]\n",
    "\n",
    "    df_metrics_grouped_season = df_metrics_grouped.loc[df_metrics_grouped['season'] == season]\n",
    "\n",
    "    df = get_best_model_per_scale_and_horizon(df_metrics_grouped_season, metric_of_interest)\n",
    "\n",
    "    shape2model = {v: k for k, v in model2shape.items()}\n",
    "\n",
    "    # Map the colors and shapes to the DataFrame\n",
    "    df['shape'] = df['model'].map(model2shape)\n",
    "\n",
    "    for scale, df_scale in df.groupby('scale'):\n",
    "        for shape in set(df_scale['shape']):\n",
    "            x = df_scale.loc[(df_scale['shape'] == shape), 'horizon_in_hours']\n",
    "            y = df_scale.loc[(df_scale['shape'] == shape), 'scale']\n",
    "            label = f'{shape2model[shape]}'\n",
    "            scatter = ax.scatter(x, y, marker=shape, label=label, color=model2color[shape2model[shape]])\n",
    "            if label not in legend_labels:\n",
    "                legend_handles.append(scatter)\n",
    "                legend_labels.append(label)\n",
    "\n",
    "    # Set the x ticks and labels\n",
    "    ax.set_xticks([1, 4, 8, 24, 48])\n",
    "    ax.set_xlabel('Forecast Horizon (hours)')\n",
    "    \n",
    "    #ax.set_yticklabels(sorted(ax.get_yticklabels(), key=lambda x: x.get_text()))\n",
    "\n",
    "\n",
    "    # Set the y label\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Spatial Scale')\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    ax.set_title(f'{season}')\n",
    "\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "fig.legend(handles=legend_handles, labels=legend_labels, title='Model', loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=2, frameon=True)\n",
    "\n",
    "fig.suptitle(f'Best Model by {metric_dict[metric_of_interest]}')\n",
    "# Adjust the spacing between subplots\n",
    "#fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based models vs. Deep learning models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these:\n",
    "\n",
    "spatial_scale = 'village'\n",
    "metric_of_interest = 'rmse_skill_score'\n",
    "\n",
    "dfs_sorted_plot = dfs_sorted.copy()\n",
    "keys = list(dfs_sorted_plot.keys())\n",
    "for key in keys:\n",
    "    if not spatial_scale in key:\n",
    "        del dfs_sorted_plot[key]\n",
    "\n",
    "\n",
    "# Define colors and shapes based on the season and model\n",
    "color2season = {v: k for k, v in season2color.items()}\n",
    "shape2model = {v: k for k, v in model2shape.items()}\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(dfs_sorted_plot), figsize=(5*(len(dfs_sorted_plot)),5), sharex=True, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Create a list to store the handles and labels for the legend\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    # Map the colors and shapes to the DataFrame\n",
    "    name, df = list(dfs_sorted_plot.items())[i]\n",
    "    # exclude 24 hour persistence\n",
    "    df = df.loc[df['model'] != '48-Hour Persistence']\n",
    "    df['group'] = df['model'].map(model2group)\n",
    "    df = df.groupby(['group', 'horizon_in_hours', 'season']).mean().reset_index()\n",
    "    df['color'] = df['season'].map(season2color)\n",
    "    df['shape'] = df['group'].map(group2shape)\n",
    "    \n",
    "    \n",
    "    for shape in set(df['shape']):\n",
    "        for color in set(df.loc[df['shape'] == shape, 'color']):\n",
    "            x = df.loc[(df['shape'] == shape) & (df['color'] == color), 'horizon_in_hours']\n",
    "            y = df.loc[(df['shape'] == shape) & (df['color'] == color), metric_of_interest]\n",
    "            label = f'{shape2group[shape]} ({color2season[color]})'\n",
    "            scatter = ax.scatter(x, y, c=color, marker=shape, label=label)\n",
    "            if label not in legend_labels:\n",
    "                legend_handles.append(scatter)\n",
    "                legend_labels.append(label)\n",
    "\n",
    "    # Set the x ticks and labels\n",
    "    ax.set_xticks([1, 4, 8, 24, 48])\n",
    "    ax.set_xlabel('Forecast Horizon (hours)')\n",
    "\n",
    "    # Set the y label\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(f'{metric_dict[metric_of_interest]}')\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    ax.set_title(f'{name.split(\"in\")[-1].replace(\"_\", \" \")}')\n",
    "\n",
    "    # Add grid for each subplot\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add a horizontal red dashed line at y = 0\n",
    "    if metric_of_interest == 'rmse_skill_score':\n",
    "        ax.axhline(y=0, color='red', linestyle='--')\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "fig.legend(handles=legend_handles, labels=legend_labels, title='Model', loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=5, frameon=True)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_of_interest = 'mape'\n",
    "\n",
    "df_metrics_all_scales = pd.DataFrame()\n",
    "\n",
    "for scale, df in dfs_sorted.items():\n",
    "    scale = scale.split('in')[0]\n",
    "    df['scale'] = scale\n",
    "    df_metrics_all_scales = df_metrics_all_scales.append(df)\n",
    "\n",
    "# marginalize over the season\n",
    "df_metrics_grouped = df_metrics_all_scales.groupby(['scale', 'model', 'horizon_in_hours']).mean()[[metric_of_interest]].reset_index()\n",
    "\n",
    "# extract the model with the best performance for each scale and horizon\n",
    "df_metrics_grouped = df_metrics_grouped.sort_values(by=['scale', metric_of_interest], ascending=False if metric_of_interest == 'rmse_skill_score' else True)\n",
    "df_metrics_grouped = df_metrics_grouped.drop_duplicates(subset=['scale', 'horizon_in_hours'], keep='first')\n",
    "df_metrics_grouped = df_metrics_grouped.sort_values(by=['scale', 'horizon_in_hours'])\n",
    "df_metrics_grouped = df_metrics_grouped.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Define colors and shapes based on the season and model\n",
    "df = df_metrics_grouped\n",
    "shape2model = {v: k for k, v in model2shape.items()}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a list to store the handles and labels for the legend\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "\n",
    "# Map the colors and shapes to the DataFrame\n",
    "df['group'] = df['model'].map(model2group)\n",
    "df = df.groupby(['group', 'horizon_in_hours', 'scale']).mean().reset_index()\n",
    "\n",
    "df['shape'] = df['group'].map(group2shape)\n",
    "\n",
    "for scale, df_scale in df.groupby('scale'): # this for loop is to make sure the order of scales is from county to neighborhood\n",
    "    for shape in set(df_scale['shape']):\n",
    "        x = df_scale.loc[(df_scale['shape'] == shape), 'horizon_in_hours']\n",
    "        y = df_scale.loc[(df_scale['shape'] == shape), 'scale']\n",
    "        label = f'{shape2group[shape]}'\n",
    "        scatter = ax.scatter(x, y, marker=shape, label=label, color=group2color[shape2group[shape]])\n",
    "        if label not in legend_labels:\n",
    "            legend_handles.append(scatter)\n",
    "            legend_labels.append(label)\n",
    "\n",
    "# Set the x ticks and labels\n",
    "ax.set_xticks([1, 4, 8, 24, 48])\n",
    "ax.set_xlabel('Forecast Horizon (hours)')\n",
    "\n",
    "ax.set_ylabel('Spatial Scale')\n",
    "\n",
    "# Set the title for each subplot\n",
    "fig.suptitle(f'Best Model by {metric_dict[metric_of_interest]}')\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "fig.legend(handles=legend_handles, labels=legend_labels, title='Model', loc='lower center', bbox_to_anchor=(0.6, -0.25), ncol=2, frameon=True)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "for format in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(os.getcwd(),'imgs','figures',f'plot_1_overview_across_scales_{metric_of_interest}.{format}'), bbox_inches='tight')\n",
    "\n",
    "#wandb.log({f'plot_1_overview_across_scales_{metric_of_interest}': fig})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results_in': 'results_synthesis',\n",
       " '3_villageinvillage_2': '3_village_village_2_60min',\n",
       " '3_villageinvillage_1': '3_village_village_1_60min',\n",
       " '3_villageinvillage_0': '3_village_village_0_60min',\n",
       " '2_townintown_2': '2_town_town_2_60min',\n",
       " '2_townintown_1': '2_town_town_1_60min',\n",
       " '2_townintown_0': '2_town_town_0_60min',\n",
       " '1_countyinSacramento': '1_county_Sacramento_60min',\n",
       " '1_countyinNew_York': '1_county_New_York_60min',\n",
       " '1_countyinLos_Angeles': '1_county_Los_Angeles_60min',\n",
       " '4_neighborhoodingermany': '4_neighborhood_germany_60min'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these\n",
    "run_to_visualize = list(name_id_dict.keys())[-1]\n",
    "season = 'Summer'\n",
    "\n",
    "scale = run_to_visualize.split('_')[1].split('in')[0]\n",
    "unit = scale2unit[scale]\n",
    "conversion = unit2kWh[unit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_file_names(project_name, name_id_dict, run_to_visualize, season)\n",
    "\n",
    "side_by_side_plots_dict= download_plotly_plots(get_latest_plotly_plots(files))\n",
    "\n",
    "df_all = side_by_side_df(side_by_side_plots_dict)\n",
    "\n",
    "df_all *= conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.iloc[:,-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyomo.environ import (\n",
    "    ConcreteModel,\n",
    "    Set,\n",
    "    Param,\n",
    "    Var,\n",
    "    Constraint,\n",
    "    Objective,\n",
    "    Reals,  # type: ignore\n",
    "    NonNegativeReals,  # type: ignore\n",
    ")\n",
    "from pyomo.opt import SolverFactory\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import wandb\n",
    "from utils import infer_frequency\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_forecasts(df, h, fc_type, horizon):\n",
    "    df = df.loc[(df.index > h) & (df.index < (h + timedelta(hours=horizon + 1)))]\n",
    "    fct = df[fc_type].to_list()\n",
    "    return fct\n",
    "\n",
    "\n",
    "def construct_fc_types(df_fc):\n",
    "    fc_types = {}\n",
    "    for col in df_fc.iloc[:, :-1].columns:\n",
    "        horizon = re.findall(r\"\\d+\", col)[0]\n",
    "        fc_types[col] = int(horizon)\n",
    "\n",
    "    fc_types[df_fc.columns[-1]] = max(list(fc_types.values()))\n",
    "    return fc_types\n",
    "\n",
    "\n",
    "def run_opt(\n",
    "    load_forecast,\n",
    "    prices,\n",
    "    bss_energy,\n",
    "    bss_duration,\n",
    "    bss_eff,\n",
    "    bss_size,\n",
    "    monthly_peak,\n",
    "    tier_load_magnitude,\n",
    "    tier2_multiplier,\n",
    "    peak_cost,\n",
    "):\n",
    "    ################################\n",
    "    # MPC optimization model\n",
    "    ################################\n",
    "    m = ConcreteModel()\n",
    "    m.T = Set(initialize=list(range(len(load_forecast))))\n",
    "\n",
    "    # Params\n",
    "    m.energy_prices = Param(m.T, initialize=prices)\n",
    "    m.demand = Param(m.T, initialize=load_forecast)\n",
    "    m.bss_size = Param(initialize=bss_size)\n",
    "    m.bss_eff = Param(initialize=bss_eff)\n",
    "    m.bss_energy_start = Param(initialize=bss_energy)\n",
    "    m.bss_max_pow = Param(initialize=bss_size / bss_duration)\n",
    "    m.monthly_peak = Param(initialize=monthly_peak)\n",
    "    m.tier_load_magnitude = Param(initialize=tier_load_magnitude)\n",
    "    m.tier2_multiplier = Param(initialize=tier2_multiplier)\n",
    "    m.peak_cost = Param(initialize=peak_cost)\n",
    "\n",
    "    # variables\n",
    "    m.net_load = Var(m.T, domain=Reals)\n",
    "    m.tier1_net_load = Var(m.T, domain=Reals)\n",
    "    m.tier2_net_load = Var(m.T, domain=NonNegativeReals)\n",
    "    m.peak = Var(domain=NonNegativeReals)\n",
    "    m.dev_peak_plus = Var(domain=NonNegativeReals)\n",
    "    m.dev_peak_minus = Var(domain=NonNegativeReals)\n",
    "    m.bss_p_ch = Var(m.T, domain=Reals)\n",
    "    m.bss_en = Var(m.T, domain=NonNegativeReals)\n",
    "\n",
    "    def energy_balance(m, t):\n",
    "        return m.net_load[t] == m.bss_eff * m.bss_p_ch[t] + m.demand[t]\n",
    "\n",
    "    m.energy_balance = Constraint(m.T, rule=energy_balance)\n",
    "\n",
    "    def tier_load_definition(m, t):\n",
    "        return m.net_load[t] == m.tier1_net_load[t] + m.tier2_net_load[t]\n",
    "\n",
    "    m.tier_load_definition = Constraint(m.T, rule=tier_load_definition)\n",
    "\n",
    "    def tier_load_limit(m, t):\n",
    "        return m.tier1_net_load[t] <= m.tier_load_magnitude\n",
    "\n",
    "    m.tier_load_limit = Constraint(m.T, rule=tier_load_limit)\n",
    "\n",
    "    def operation_peak(m, t):\n",
    "        return m.peak >= m.net_load[t]\n",
    "\n",
    "    m.operation_peak = Constraint(m.T, rule=operation_peak)\n",
    "\n",
    "    def relevant_peak(m):\n",
    "        return m.peak - m.monthly_peak == m.dev_peak_plus - m.dev_peak_minus\n",
    "\n",
    "    m.relevant_peak = Constraint(rule=relevant_peak)\n",
    "\n",
    "    def bat_soc(m, t):\n",
    "        if t == 0:\n",
    "            return m.bss_en[t] == m.bss_energy_start + m.bss_p_ch[t]\n",
    "        else:\n",
    "            return m.bss_en[t] == m.bss_en[t - 1] + m.bss_p_ch[t]\n",
    "\n",
    "    m.bat_soc = Constraint(m.T, rule=bat_soc)\n",
    "\n",
    "    def bat_lim_energy(m, t):\n",
    "        return m.bss_en[t] <= m.bss_size\n",
    "\n",
    "    m.bat_lim_energy = Constraint(m.T, rule=bat_lim_energy)\n",
    "\n",
    "    def bat_lim_power_pos(m, t):\n",
    "        return m.bss_p_ch[t] <= m.bss_max_pow\n",
    "\n",
    "    m.bat_lim_power_pos = Constraint(m.T, rule=bat_lim_power_pos)\n",
    "\n",
    "    def bat_lim_power_neg(m, t):\n",
    "        return -m.bss_max_pow <= m.bss_p_ch[t]\n",
    "\n",
    "    m.bat_lim_power_neg = Constraint(m.T, rule=bat_lim_power_neg)\n",
    "\n",
    "    def cost(m):\n",
    "        return (\n",
    "            sum(m.tier1_net_load[t] * m.energy_prices[t] for t in m.T)\n",
    "            + sum(\n",
    "                m.tier2_net_load[t] * m.energy_prices[t] * m.tier2_multiplier\n",
    "                for t in m.T\n",
    "            )\n",
    "            + (m.dev_peak_plus + m.monthly_peak) * m.peak_cost\n",
    "        )\n",
    "\n",
    "    m.ObjectiveFunction = Objective(rule=cost)\n",
    "\n",
    "    opt = SolverFactory(\"cplex\")\n",
    "    results = opt.solve(m)\n",
    "\n",
    "    # get results\n",
    "    res_df = pd.DataFrame(index=list(m.T))\n",
    "    for v in [m.net_load, m.tier1_net_load, m.tier2_net_load, m.bss_p_ch, m.bss_en]:\n",
    "        res_df = res_df.join(pd.Series(v.get_values(), name=v.getname()))\n",
    "\n",
    "    # just returns the first (next time) set-point\n",
    "    sp = res_df.iloc[0].to_dict()\n",
    "\n",
    "    return sp\n",
    "\n",
    "\n",
    "def run_operations(\n",
    "    hours_of_simulation,\n",
    "    fc,\n",
    "    fc_type,\n",
    "    prices,\n",
    "    horizon,\n",
    "    bat_size_kwh,\n",
    "    bat_duration,\n",
    "    bss_eff,\n",
    "    initial_soc,\n",
    "    tier_load_magnitude,\n",
    "    tier2_multiplier,\n",
    "    peak_cost,\n",
    "):\n",
    "    # function to run operations of given a forecast and system data\n",
    "\n",
    "    # initializing monthly peak (it will store the historical peak)\n",
    "    peak = tier_load_magnitude  # initializing monthly peak\n",
    "\n",
    "    # initialize energy in the battery with the initial soc\n",
    "    energy_in_the_battery = bat_size_kwh * initial_soc\n",
    "\n",
    "    operations = {}\n",
    "    for t in fc.index[:hours_of_simulation]:\n",
    "        # get load forecast as a list\n",
    "        load = get_forecasts(df=fc, h=t, fc_type=fc_type, horizon=horizon)\n",
    "\n",
    "        # get the energy prices as a list\n",
    "        ep = get_forecasts(\n",
    "            df=prices, h=t, fc_type=\"ep\", horizon=horizon\n",
    "        )\n",
    "\n",
    "        # gets a set_point for the next interval based on the MPC optimization\n",
    "        # the horizon of the optimization is given by the length of the forecast\n",
    "        set_point = run_opt(\n",
    "            load_forecast=load,\n",
    "            prices=ep,\n",
    "            bss_energy=energy_in_the_battery,\n",
    "            bss_size=bat_size_kwh,\n",
    "            bss_duration=bat_duration,\n",
    "            monthly_peak=peak,\n",
    "            tier_load_magnitude=tier_load_magnitude,\n",
    "            tier2_multiplier=tier2_multiplier,\n",
    "            peak_cost=peak_cost,\n",
    "            bss_eff=bss_eff,\n",
    "        )\n",
    "\n",
    "        # implement set point in time, calculate net and tier load\n",
    "        set_point_time = t + timedelta(hours=1)\n",
    "        net_load = fc.loc[set_point_time][\"Ground Truth\"] + set_point[\"bss_p_ch\"]\n",
    "        tier1_load = (\n",
    "            net_load if net_load <= tier_load_magnitude else tier_load_magnitude\n",
    "        )\n",
    "        tier2_load = (\n",
    "            0 if net_load <= tier_load_magnitude else net_load - tier_load_magnitude\n",
    "        )\n",
    "\n",
    "        # implement peak condition\n",
    "        if peak < net_load:\n",
    "            peak = net_load\n",
    "        set_point.update(\n",
    "            {\n",
    "                \"opr_net_load\": net_load,\n",
    "                \"opr_tier1_load\": tier1_load,\n",
    "                \"opr_tier2_load\": tier2_load,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # update energy in the battery\n",
    "        energy_in_the_battery = set_point[\"bss_en\"]\n",
    "\n",
    "        operations.update({set_point_time: set_point})\n",
    "\n",
    "    return pd.DataFrame(operations).T\n",
    "\n",
    "\n",
    "def scale_by_gt(df):\n",
    "    \"\"\"Scale the predictions and ground truth by the max and min of the ground truth\"\"\"\n",
    "\n",
    "    gt_max = df[\"Ground Truth\"].max()\n",
    "    gt_min = df[\"Ground Truth\"].min()\n",
    "\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[\"Ground Truth\"] = (df_scaled[\"Ground Truth\"] - gt_min) / (gt_max - gt_min)\n",
    "\n",
    "    for col in df_scaled.columns:\n",
    "        if col != \"Ground Truth\":\n",
    "            df_scaled[col] = (df_scaled[col] - gt_min) / (gt_max - gt_min)\n",
    "\n",
    "    return df_scaled, gt_max, gt_min\n",
    "\n",
    "\n",
    "def generate_ep_profile(df, hour_shift=1, mu=0.05, sigma=0.1):\n",
    "    \"\"\"Generate electricity price profiles based on the ground truth of the load\"\"\"\n",
    "\n",
    "    timesteps_per_hour = int(infer_frequency(df) // 60)\n",
    "    shift_in_timesteps = hour_shift * timesteps_per_hour\n",
    "    # step 1: shift the ground truth by n hours\n",
    "    ep1 = df[\"Ground Truth\"].shift(shift_in_timesteps)\n",
    "\n",
    "    # step 2: add a random noise to it\n",
    "    ep2 = ep1 + np.random.normal(mu, sigma, len(ep1))\n",
    "    # step 3: smooth it\n",
    "    ep3 = ep2.ewm(span=timesteps_per_hour * 6).mean().fillna(method=\"bfill\")\n",
    "    # step 4: adjust to be between roughly 0 and 0.3\n",
    "    ep4 = ep3.to_frame(\"ep\") / 3\n",
    "    return ep4\n",
    "\n",
    "\n",
    "def run_mpc(df_fc):\n",
    "    ##############################################\n",
    "    # input parameters\n",
    "    #############################################\n",
    "\n",
    "    hours_of_simulation = 600\n",
    "\n",
    "    timesteps_per_hour = infer_frequency(df_fc)\n",
    "    df_scaled, gt_max, gt_min = scale_by_gt(df_fc)\n",
    "\n",
    "    # battery parameters\n",
    "    initial_soc = 0.5  # initial state of charge of the battery (no unit)\n",
    "    bat_size_kwh = 2 * timesteps_per_hour  # size of the battery in kWh\n",
    "    c_rate = 0.5  # C-rate of the battery\n",
    "    bat_duration = (\n",
    "        c_rate * bat_size_kwh\n",
    "    )  # battery duration (Max_kW = bat_size/duration)\n",
    "    bat_efficiency = 0.95  # charging and discharging efficiency of the battery\n",
    "\n",
    "    # electricity price parameters\n",
    "    tier_limit = df_scaled[\"Ground Truth\"].quantile(0.95)\n",
    "    ep = generate_ep_profile(df=df_scaled)\n",
    "    tier2_cost_multiplier = 1.5  # cost multiplication of the tier 2 load\n",
    "    cost_of_peak = 5.0  # cost of the monthly peak\n",
    "\n",
    "    fc_types = construct_fc_types(df_fc=df_fc)\n",
    "    ##############################################\n",
    "    # simulation starts here\n",
    "    ##############################################\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for fc_type, horizon in fc_types.items():\n",
    "        print(f\"running {fc_type}\")\n",
    "\n",
    "        fc_result = run_operations(\n",
    "            hours_of_simulation=hours_of_simulation,\n",
    "            fc=df_scaled,  # forecast table\n",
    "            fc_type=fc_type,  # label of forecast type\n",
    "            prices=ep,  # electricity prices\n",
    "            horizon=horizon,\n",
    "            bat_size_kwh=bat_size_kwh,\n",
    "            bat_duration=bat_duration,\n",
    "            initial_soc=initial_soc,\n",
    "            bss_eff=bat_efficiency,\n",
    "            tier_load_magnitude=tier_limit,\n",
    "            tier2_multiplier=tier2_cost_multiplier,\n",
    "            peak_cost=cost_of_peak,\n",
    "        )\n",
    "\n",
    "        # add the forecast label to the forecast operation results\n",
    "        for k in fc_result:\n",
    "            fc_result[k + f\"_{fc_type}\"] = fc_result[k]  # type: ignore\n",
    "            fc_result = fc_result.drop(k, axis=1)\n",
    "\n",
    "        # build the operation results table\n",
    "        if results.shape[0] == 0:\n",
    "            results = pd.concat([results, fc_result])\n",
    "        else:\n",
    "            results = results.join(fc_result)\n",
    "\n",
    "    # calculate operation costs of each forecast\n",
    "    cost_results = {}\n",
    "    results = results.join(df_scaled[[\"Ground Truth\"]]).join(ep)\n",
    "    for fc_type in fc_types.keys():\n",
    "        tier1 = (\n",
    "            results[f\"opr_tier1_load_{fc_type}\"] * results[\"ep\"]\n",
    "        ).sum()\n",
    "\n",
    "        tier2 = (\n",
    "            results[f\"opr_tier2_load_{fc_type}\"]\n",
    "            * results[\"ep\"]\n",
    "            * tier2_cost_multiplier\n",
    "        ).sum()\n",
    "\n",
    "        peak = results[f\"opr_net_load_{fc_type}\"].max() * cost_of_peak\n",
    "\n",
    "        cost_results.update(\n",
    "            {\n",
    "                fc_type: {\n",
    "                    \"horizon\": fc_types[fc_type],\n",
    "                    \"tier1\": tier1,\n",
    "                    \"tier2\": tier2,\n",
    "                    \"peak\": peak,\n",
    "                    \"total\": tier1 + tier2 + peak,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    cost_results = pd.DataFrame(cost_results).T\n",
    "\n",
    "    # write results, TODO: replace with wandb logging and return results\n",
    "    cost_results.to_csv(\"data/results/cost_results.csv\")\n",
    "    results.to_csv(\"data/results/operation_results.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running NBEATSModel Summer - Horizon: 8 Hours\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_mpc(df_all)\n",
      "Cell \u001b[0;32mIn[16], line 295\u001b[0m, in \u001b[0;36mrun_mpc\u001b[0;34m(df_fc)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mfor\u001b[39;00m fc_type, horizon \u001b[39min\u001b[39;00m fc_types\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    293\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrunning \u001b[39m\u001b[39m{\u001b[39;00mfc_type\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m     fc_result \u001b[39m=\u001b[39m run_operations(\n\u001b[1;32m    296\u001b[0m         hours_of_simulation\u001b[39m=\u001b[39;49mhours_of_simulation,\n\u001b[1;32m    297\u001b[0m         fc\u001b[39m=\u001b[39;49mdf_fc,  \u001b[39m# forecast table\u001b[39;49;00m\n\u001b[1;32m    298\u001b[0m         fc_type\u001b[39m=\u001b[39;49mfc_type,  \u001b[39m# label of forecast type\u001b[39;49;00m\n\u001b[1;32m    299\u001b[0m         prices\u001b[39m=\u001b[39;49mep,  \u001b[39m# electricity prices\u001b[39;49;00m\n\u001b[1;32m    300\u001b[0m         horizon\u001b[39m=\u001b[39;49mhorizon,\n\u001b[1;32m    301\u001b[0m         bat_size_kwh\u001b[39m=\u001b[39;49mbat_size_kwh,\n\u001b[1;32m    302\u001b[0m         bat_duration\u001b[39m=\u001b[39;49mbat_duration,\n\u001b[1;32m    303\u001b[0m         initial_soc\u001b[39m=\u001b[39;49minitial_soc,\n\u001b[1;32m    304\u001b[0m         bss_eff\u001b[39m=\u001b[39;49mbat_efficiency,\n\u001b[1;32m    305\u001b[0m         tier_load_magnitude\u001b[39m=\u001b[39;49mtier_limit,\n\u001b[1;32m    306\u001b[0m         tier2_multiplier\u001b[39m=\u001b[39;49mtier2_cost_multiplier,\n\u001b[1;32m    307\u001b[0m         peak_cost\u001b[39m=\u001b[39;49mcost_of_peak,\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[39m# add the forecast label to the forecast operation results\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m fc_result:\n",
      "Cell \u001b[0;32mIn[16], line 201\u001b[0m, in \u001b[0;36mrun_operations\u001b[0;34m(hours_of_simulation, fc, fc_type, prices, horizon, bat_size_kwh, bat_duration, bss_eff, initial_soc, tier_load_magnitude, tier2_multiplier, peak_cost)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m# implement set point in time, calculate net and tier load\u001b[39;00m\n\u001b[1;32m    200\u001b[0m set_point_time \u001b[39m=\u001b[39m t \u001b[39m+\u001b[39m timedelta(hours\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m net_load \u001b[39m=\u001b[39m fc\u001b[39m.\u001b[39;49mloc[set_point_time][\u001b[39m\"\u001b[39;49m\u001b[39mGround Truth\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m+\u001b[39;49m set_point[\u001b[39m\"\u001b[39;49m\u001b[39mbss_p_ch\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    202\u001b[0m tier1_load \u001b[39m=\u001b[39m (\n\u001b[1;32m    203\u001b[0m     net_load \u001b[39mif\u001b[39;00m net_load \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tier_load_magnitude \u001b[39melse\u001b[39;00m tier_load_magnitude\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    205\u001b[0m tier2_load \u001b[39m=\u001b[39m (\n\u001b[1;32m    206\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m net_load \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tier_load_magnitude \u001b[39melse\u001b[39;00m net_load \u001b[39m-\u001b[39m tier_load_magnitude\n\u001b[1;32m    207\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "run_mpc(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
